{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##importing Basic libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pandas import DataFrame, Series\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model, naive_bayes\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import svm\n",
    "import bokeh as bk\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "import plotly\n",
    "import chart_studio.plotly as py\n",
    "from chart_studio.plotly import plot, iplot \n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objects as go\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "import pybaseball as pyb\n",
    "from pybaseball import statcast\n",
    "from pybaseball import statcast_pitcher\n",
    "from pybaseball import statcast_batter\n",
    "from pybaseball import statcast_pitcher_exitvelo_barrels\n",
    "from pybaseball import statcast_batter_exitvelo_barrels\n",
    "from pybaseball import statcast_batter_expected_stats\n",
    "from pybaseball import statcast_pitcher_expected_stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pwlf as pwlf\n",
    "#import matplotlib.backends\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(\"/Users/johndavis/Desktop/College_Updated_5_14.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the highest value in RelSpeed column\n",
    "df3['RelSpeed'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe with only the columns we want for Analysis\n",
    "dft = df3[['Pitcher','PitcherTeam','TaggedPitchType','PitchCall','PlayResult','RelSpeed','SpinRate','RelHeight','RelSide','Extension','InducedVertBreak', 'HorzBreak','PlateLocHeight','PlateLocSide']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fastballs = 'Fastball', 'Sinker', 'TwoSeamFastBall', 'FourSeamFastBall', 'OneSeamFastBall'\n",
    "dfb2 = dft[dft.TaggedPitchType.isin(['Fastball', 'Sinker', 'TwoSeamFastBall', 'FourSeamFastBall', 'OneSeamFastBall'])]\n",
    "#sliders = 'Slider', 'Cutter'\n",
    "dsl2 = dft[dft.TaggedPitchType.isin(['Slider', 'Cutter'])]\n",
    "#curveballs = 'Curveball', 'KnuckleCurve'\n",
    "dcb2 = dft[dft.TaggedPitchType.isin(['Curveball', 'KnuckleCurve'])]\n",
    "#changeups = 'Changeup', 'Splitter', 'Forkball', 'Screwball'\n",
    "dch2 = dft[dft.TaggedPitchType.isin(['ChangeUp'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column called ABS_Horizontal with the absolute value of HorzBreak  in dfb2\n",
    "dfb2['ABS_Horizontal'] = abs(dfb2['HorzBreak'])\n",
    "dsl2['ABS_Horizontal'] = abs(dsl2['HorzBreak'])\n",
    "dcb2['ABS_Horizontal'] = abs(dcb2['HorzBreak'])\n",
    "dch2['ABS_Horizontal'] = abs(dch2['HorzBreak'])\n",
    "#create a new column called ABS_relside with the absolute value of RelSide in dfb2\n",
    "dfb2['ABS_RelSide'] = abs(dfb2['RelSide'])\n",
    "dsl2['ABS_RelSide'] = abs(dsl2['RelSide'])\n",
    "dcb2['ABS_RelSide'] = abs(dcb2['RelSide'])\n",
    "dch2['ABS_RelSide'] = abs(dch2['RelSide'])\n",
    "#create a new column called differential break which is the absolute value of InducedVertBreak - ABS_Horizontal\n",
    "dfb2['differential_break'] = abs(dfb2['InducedVertBreak'] - dfb2['ABS_Horizontal'])\n",
    "dsl2['differential_break'] = abs(dsl2['InducedVertBreak'] - dsl2['ABS_Horizontal'])\n",
    "dcb2['differential_break'] = abs(dcb2['InducedVertBreak'] - dcb2['ABS_Horizontal'])\n",
    "dch2['differential_break'] = abs(dch2['InducedVertBreak'] - dch2['ABS_Horizontal'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete all rows with nan values\n",
    "dfb2 = dfb2.dropna()\n",
    "dsl2 = dsl2.dropna()\n",
    "dcb2 = dcb2.dropna()\n",
    "dch2 = dch2.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset index    \n",
    "dfb2 = dfb2.reset_index(drop=True)\n",
    "dsl2 = dsl2.reset_index(drop=True)\n",
    "dcb2 = dcb2.reset_index(drop=True)\n",
    "dch2 = dch2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PitchCall unique values\n",
    "dft['PitchCall'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change 'SwinginStrike', 'StriekSwinging' in PitchCall to 'StrikeSwinging'\n",
    "dft['PitchCall'] = dft['PitchCall'].replace(['SwinginStrike', 'StriekSwinging'], 'StrikeSwinging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new dataframe with only PitchCall StrikeSwinging, InPlay, FoulBall and call it df_Swing\n",
    "df_Swing = dft[(dft['PitchCall'] == 'StrikeSwinging') | (dft['PitchCall'] == 'InPlay') | (dft['PitchCall'] == 'FoulBall')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dummy variable for PitchCall with StrikeSwinging = 1 and InPlay, FoulBall = 0\n",
    "df_Swing['Whiff'] = df_Swing['PitchCall'].replace(['StrikeSwinging'], 1)\n",
    "df_Swing['Whiff'] = df_Swing['PitchCall'].replace(['InPlay', 'FoulBall'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace strike swinging with 1 and inplay, foulball with 0\n",
    "df_Swing['Whiff'] = df_Swing['Whiff'].replace(['StrikeSwinging'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column called ABS_Horizontal with the absolute value of HorzBreak\n",
    "df_Swing['ABS_Horizontal'] = abs(df_Swing['HorzBreak'])\n",
    "#create a new column called ABS_RelSide with the absolute value of RelSide\n",
    "df_Swing['ABS_RelSide'] = abs(df_Swing['RelSide'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column called differential break which is the absolute value of InducedVertBreak - ABS_Horizontal\n",
    "df_Swing['differential_break'] = abs(df_Swing['InducedVertBreak'] - df_Swing['ABS_Horizontal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taggedpitchtype unique values\n",
    "df_Swing['TaggedPitchType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove any row with Nan for any of the columns\n",
    "df_Swing = df_Swing.dropna()\n",
    "#reset the index\n",
    "df_Swing = df_Swing.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate dataframes for each pitch type \n",
    "#fastballs = 'Fastball', 'Sinker', 'TwoSeamFastBall', 'FourSeamFastBall', 'OneSeamFastBall'\n",
    "df_Fastball = df_Swing[(df_Swing['TaggedPitchType'] == 'Fastball') | (df_Swing['TaggedPitchType'] == 'Sinker') | (df_Swing['TaggedPitchType'] == 'TwoSeamFastBall') | (df_Swing['TaggedPitchType'] == 'FourSeamFastBall') | (df_Swing['TaggedPitchType'] == 'OneSeamFastBall')]\n",
    "df_Fastball = df_Fastball.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#curveballs = 'Curveball', 'KnuckleCurve'\n",
    "df_Curveball = df_Swing[(df_Swing['TaggedPitchType'] == 'Curveball') | (df_Swing['TaggedPitchType'] == 'KnuckleCurve')]\n",
    "df_Curveball = df_Curveball.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Slider = 'Slider'\n",
    "df_Slider = df_Swing[(df_Swing['TaggedPitchType'] == 'Slider')]\n",
    "df_Slider = df_Slider.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Changeup = 'Changeup'\n",
    "df_Changeup = df_Swing[(df_Swing['TaggedPitchType'] == 'ChangeUp')]\n",
    "df_Changeup = df_Changeup.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Swing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the FB expected whiff rate\n",
    "X = df_Fastball[['RelSpeed', 'SpinRate','differential_break','RelHeight', 'ABS_RelSide', 'Extension']]\n",
    "y = df_Fastball['Whiff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the CB expected whiff rate\n",
    "X1 = df_Curveball[['RelSpeed', 'SpinRate', 'InducedVertBreak', 'ABS_Horizontal','RelHeight', 'ABS_RelSide', 'Extension']]\n",
    "y1 = df_Curveball['Whiff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the SL expected whiff rate\n",
    "X2 = df_Slider[['RelSpeed', 'SpinRate', 'InducedVertBreak', 'ABS_Horizontal','RelHeight', 'ABS_RelSide', 'Extension']]\n",
    "y2 = df_Slider['Whiff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the CH expected whiff rate\n",
    "X3 = df_Changeup[['RelSpeed', 'SpinRate', 'InducedVertBreak', 'ABS_Horizontal','RelHeight', 'ABS_RelSide', 'Extension']]\n",
    "y3 = df_Changeup['Whiff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.25, random_state=101)\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.25, random_state=101)\n",
    "\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.25, random_state=101)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create the neural network model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost for fastball\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest for fastball\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastball_model = train_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost for curveball\n",
    "xgb_model1 = XGBClassifier()\n",
    "xgb_model1.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest for curveball\n",
    "rfc1 = RandomForestClassifier(n_estimators=100)\n",
    "rfc1.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CURVEBALL MODEL\n",
    "curveball_model = train_model(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost for slider\n",
    "xgb_model2 = XGBClassifier()\n",
    "xgb_model2.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest for slider\n",
    "rfc2 = RandomForestClassifier(n_estimators=100)\n",
    "rfc2.fit(X2_train, y2_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SLIDER MODEL\n",
    "slider_model = train_model(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost for changeup\n",
    "xgb_model3 = XGBClassifier()\n",
    "xgb_model3.fit(X3_train, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest for changeup\n",
    "rfc3 = RandomForestClassifier(n_estimators=100)\n",
    "rfc3.fit(X3_train, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHANGEUP MODEL\n",
    "changeup_model = train_model(X3, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find rmse for fastball\n",
    "predictions = xgb_model.predict(X_test)\n",
    "print('XGBoost Fastball RMSE:', np.sqrt(mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find rmse for fastball\n",
    "predictions = rfc.predict(X_test)\n",
    "print('Random Forest Fastball RMSE:', np.sqrt(mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find rmse for Fastball nn\n",
    "predictions = fastball_model.predict(X_test)\n",
    "print('Neural Network Fastball RMSE:', np.sqrt(mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column in the dfb2 dataframe called xWhiff_xg and set it equal to the predicted probability of a whiff as predicted by the xgboost model\n",
    "dfb2['xWhiff_xg'] = xgb_model.predict_proba(dfb2[['RelSpeed', 'SpinRate', 'differential_break', 'RelHeight', 'ABS_RelSide', 'Extension']])[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column in the dfb2 dataframe called xWhiff_xg and set it equal to the predicted probability of a whiff as predicted by the xgboost model\n",
    "dcb2['xWhiff_xg'] = xgb_model1.predict_proba(dcb2[['RelSpeed', 'SpinRate', 'InducedVertBreak', 'ABS_Horizontal','RelHeight', 'ABS_RelSide', 'Extension']])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column in the dsl2 dataframe called xWhiff and use the model tp predict the expected whiff rate given the same variables\n",
    "dsl2['xWhiff_xg'] = xgb_model2.predict_proba(dsl2[['RelSpeed', 'SpinRate', 'InducedVertBreak', 'ABS_Horizontal','RelHeight', 'ABS_RelSide', 'Extension']])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column in the dch2 dataframe called xWhiff and use the model tp predict the expected whiff rate given the same variables\n",
    "dch2['xWhiff_xg'] = xgb_model3.predict_proba(dch2[['RelSpeed', 'SpinRate', 'InducedVertBreak', 'ABS_Horizontal','RelHeight', 'ABS_RelSide', 'Extension']])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column in the dfb2 dataframe called xWhiff_rf and set it equal to the predicted probability of a whiff as predicted by the random forest model\n",
    "dfb2['xWhiff_rf'] = rfc.predict_proba(dfb2[['RelSpeed', 'SpinRate', 'differential_break', 'RelHeight', 'ABS_RelSide', 'Extension']])[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column in the dfb2 dataframe called xWhiff_rf and set it equal to the predicted probability of a whiff as predicted by the random forest model\n",
    "dcb2['xWhiff_rf'] = rfc1.predict_proba(dcb2[['RelSpeed', 'SpinRate', 'InducedVertBreak', 'ABS_Horizontal','RelHeight', 'ABS_RelSide', 'Extension']])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column in the dsl2 dataframe called xWhiff and use the model tp predict the expected whiff rate given the same variables\n",
    "dsl2['xWhiff_rf'] = rfc2.predict_proba(dsl2[['RelSpeed', 'SpinRate', 'InducedVertBreak', 'ABS_Horizontal','RelHeight', 'ABS_RelSide', 'Extension']])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column in the dch2 dataframe called xWhiff and use the model tp predict the expected whiff rate given the same variables\n",
    "dch2['xWhiff_rf'] = rfc3.predict_proba(dch2[['RelSpeed', 'SpinRate', 'InducedVertBreak', 'ABS_Horizontal','RelHeight', 'ABS_RelSide', 'Extension']])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE NEURAL NETWORK TO PREDICT WHIFF RATE FOR FASTBALL AND ADD TO DATAFRAME\n",
    "dfb2['xWhiff_nn'] = fastball_model.predict(dfb2[['RelSpeed', 'SpinRate', 'differential_break', 'RelHeight', 'ABS_RelSide', 'Extension']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE NEURAL NETWORK TO PREDICT WHIFF RATE FOR CURVEBALL AND ADD TO DATAFRAME\n",
    "dcb2['xWhiff_nn'] = curveball_model.predict(dcb2[['RelSpeed', 'SpinRate', 'InducedVertBreak', 'ABS_Horizontal','RelHeight', 'ABS_RelSide', 'Extension']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE NEURAL NETWORK TO PREDICT WHIFF RATE FOR SLIDER AND ADD TO DATAFRAME\n",
    "dsl2['xWhiff_nn'] = slider_model.predict(dsl2[['RelSpeed', 'SpinRate', 'InducedVertBreak', 'ABS_Horizontal','RelHeight', 'ABS_RelSide', 'Extension']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE NEURAL NETWORK TO PREDICT WHIFF RATE FOR CHANGEUP AND ADD TO DATAFRAME\n",
    "dch2['xWhiff_nn'] = changeup_model.predict(dch2[['RelSpeed', 'SpinRate', 'InducedVertBreak', 'ABS_Horizontal','RelHeight', 'ABS_RelSide', 'Extension']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the average of the Three models to get the final expected whiff rate\n",
    "dfb2['xWhiff'] = (dfb2['xWhiff_xg'] + dfb2['xWhiff_rf'] + dfb2['xWhiff_nn'])/3\n",
    "dcb2['xWhiff'] = (dcb2['xWhiff_xg'] + dcb2['xWhiff_rf'] + dcb2['xWhiff_nn'])/3\n",
    "dsl2['xWhiff'] = (dsl2['xWhiff_xg'] + dsl2['xWhiff_rf'] + dsl2['xWhiff_nn'])/3\n",
    "dch2['xWhiff'] = (dch2['xWhiff_xg'] + dch2['xWhiff_rf'] + dch2['xWhiff_nn'])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the mean of the xWhiff column\n",
    "dfb2['xWhiff'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the mean of the xWhiff column\n",
    "dcb2['xWhiff'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the mean of the xWhiff column\n",
    "dsl2['xWhiff'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the mean of the xWhiff column\n",
    "dch2['xWhiff'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column in dfb2 called stuff+ which is (xWhiff / mean of xWhiff for dfb2) * 100\n",
    "dfb2['stuff+'] = (dfb2['xWhiff'] / dfb2['xWhiff'].mean()) * 100\n",
    "#create a new column in dcb2 called stuff+ which is (xWhiff / mean of xWhiff for dcb2) * 100\n",
    "dcb2['stuff+'] = (dcb2['xWhiff'] / dcb2['xWhiff'].mean()) * 100\n",
    "#create a new column in dsl2 called stuff+ which is (xWhiff / mean of xWhiff for dsl2) * 100\n",
    "dsl2['stuff+'] = (dsl2['xWhiff'] / dsl2['xWhiff'].mean()) * 100\n",
    "#create a new column in dch2 called stuff+ which is (xWhiff / mean of xWhiff for dch2) * 100\n",
    "dch2['stuff+'] = (dch2['xWhiff'] / dch2['xWhiff'].mean()) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find correlation between each xWhiff and stuff+ column\n",
    "dfb2['xWhiff_nn'].corr(dfb2['stuff+'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calulcate the mean of stuff+ for dfb2\n",
    "dfb2['stuff+'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calulcate the mean of stuff+ for dcb2\n",
    "dcb2['stuff+'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calulcate the mean of stuff+ for dsl2\n",
    "dsl2['stuff+'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calulcate the mean of stuff+ for dch2\n",
    "dch2['stuff+'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat a visualization of the mean of stuff+ for each pitch type \n",
    "plt.bar(['Fastball', 'Curveball', 'Slider', 'Changeup'], [dfb2['stuff+'].mean(), dcb2['stuff+'].mean(), dsl2['stuff+'].mean(), dch2['stuff+'].mean()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reccombine the dataframes\n",
    "College_Final_Stuff = pd.concat([dfb2, dsl2, dcb2, dch2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "College_Final_Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #group by PitcherTeam and find the mean of stuff+ for each team\n",
    "df_College_Team_AVG3 = College_Final_Stuff.groupby('PitcherTeam')['stuff+'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the values high to low\n",
    "df_College_Team_AVG3 = df_College_Team_AVG3.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change PitcherTeam to team_abbr\n",
    "df_College_Team_AVG3 = df_College_Team_AVG3.rename_axis('team_abbr').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_College_Names3 = pd.read_csv(\"/Users/johndavis/Desktop/Trackman_Names.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_College_Names3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the two dataframes by team_abbr\n",
    "df_College_Team_AVG2 = pd.merge(df_College_Team_AVG3, df_College_Names3, on='team_abbr', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only include conference, team, stuff+ and and  team_abbr,  sort by stuff+ high to low\n",
    "df_College_Team_AVG2 = df_College_Team_AVG2[['conference', 'team', 'stuff+', 'team_abbr']].sort_values(by='stuff+', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locate the team_abbr for the team you want to find the stuff+ for\n",
    "df_College_Team_AVG2.loc[df_College_Team_AVG2['team_abbr'] == 'PAC_TIG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50_college_teams = df_College_Team_AVG2.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50_college_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort values low to high\n",
    "bottom_50_college_teams = df_College_Team_AVG2.sort_values(by='stuff+', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by conference and find the mean of stuff+ for each conference\n",
    "df_College_Conference_AVG3 = df_College_Team_AVG2.groupby('conference')['stuff+'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_College_Conference_AVG3 = df_College_Conference_AVG3.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_college_teams = df_College_Team_AVG2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_conferences = df_College_Conference_AVG3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv to desktop\n",
    "top_10_college_teams.to_csv('/Users/johndavis/Desktop/top_10_college_teams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv to desktop\n",
    "top_10_conferences.to_csv('/Users/johndavis/Desktop/top_10_conferences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv to desktop \n",
    "College_Final_Stuff.to_csv(r'/Users/johndavis/Desktop/College_Final_Stuff_Full.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by pitcher and pitch type and take the average of stuff+, do not make it a multi index\n",
    "College_Final_Stuff_avg = College_Final_Stuff.groupby(['Pitcher', 'TaggedPitchType'], as_index=False)['PitcherTeam','stuff+','RelSpeed','InducedVertBreak','HorzBreak'].mean()\n",
    "#create a pitch count column which is the count of each pitch type of each pitcher from df_Swing_2\n",
    "College_Final_Stuff_avg['PitchCount'] = College_Final_Stuff.groupby(['Pitcher', 'TaggedPitchType'])['TaggedPitchType'].count().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort College_Final_Stuff_avg by stuff+ high to low\n",
    "College_Final_Stuff_avg = College_Final_Stuff_avg.sort_values(by='stuff+', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min pitch count of 200 for Fastball, Two-Seam, Four-Seam, Sinker and Min pitch count of 100 for Slider, Curveball and Changeup\n",
    "College_Final_Stuff_avg_pitch_count = College_Final_Stuff_avg[(College_Final_Stuff_avg['TaggedPitchType'] == 'Fastball') & (College_Final_Stuff_avg['PitchCount'] >= 200) | (College_Final_Stuff_avg['TaggedPitchType'] == 'Two-Seam') & (College_Final_Stuff_avg['PitchCount'] >= 200) | (College_Final_Stuff_avg['TaggedPitchType'] == 'Four-Seam') & (College_Final_Stuff_avg['PitchCount'] >= 200) | (College_Final_Stuff_avg['TaggedPitchType'] == 'Sinker') & (College_Final_Stuff_avg['PitchCount'] >= 200) | (College_Final_Stuff_avg['TaggedPitchType'] == 'Slider') & (College_Final_Stuff_avg['PitchCount'] >= 100) | (College_Final_Stuff_avg['TaggedPitchType'] == 'Curveball') & (College_Final_Stuff_avg['PitchCount'] >= 100) | (College_Final_Stuff_avg['TaggedPitchType'] == 'Changeup') & (College_Final_Stuff_avg['PitchCount'] >= 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "College_Final_Stuff_avg_pitch_count.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locate Skenes, Paul\n",
    "College_Final_Stuff_avg.loc[College_Final_Stuff_avg['Pitcher'] == 'Skenes, Paul']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#College_Final_Stuff_avg to desktop csv\n",
    "College_Final_Stuff_avg.to_csv(r'/Users/johndavis/Desktop/College_Final_Stuff_Avg.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new dataframe with minimum 100 pitches thrown\n",
    "College_Final_Stuff_avg_100_pitch_min = College_Final_Stuff_avg[College_Final_Stuff_avg['PitchCount'] >= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort by stuff+ descending\n",
    "College_Final_Stuff_avg_100_pitch_min = College_Final_Stuff_avg_100_pitch_min.sort_values(by=['stuff+'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataframe out of College_Final_Stuff_avg that averages the stuff+ for each pitcher and combines the pitch types based on the average stuff+ for each pitch and weighted by the pitch count\n",
    "College_Final_Stuff_avg_AVG2 = College_Final_Stuff_avg.groupby(['Pitcher'], as_index=False)['stuff+'].mean()\n",
    "#add the pitch count columns to the dataframe from each pitch add them together\n",
    "College_Final_Stuff_avg_AVG2['PitchCount'] = College_Final_Stuff_avg.groupby(['Pitcher'])['PitchCount'].sum().values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort by stuff+ descending\n",
    "College_Final_Stuff_avg_AVG2 = College_Final_Stuff_avg_AVG2.sort_values(by=['stuff+'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a new dataframe with 400 pitch minimum for College_Final_Stuff_avg_AVG2\n",
    "College_Final_Stuff_avg_AVG2_400_pitch_min = College_Final_Stuff_avg_AVG2[College_Final_Stuff_avg_AVG2['PitchCount'] >= 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort by stuff+ descending\n",
    "College_Final_Stuff_avg_AVG2_400_pitch_min = College_Final_Stuff_avg_AVG2_400_pitch_min.sort_values(by=['stuff+'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "College_Final_Stuff_avg_AVG2_400_pitch_min.head(25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ece8b02e9fc008d2bf4aaa30f9b06cdaffafe92b71d54bfc844a320ee0701ab8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
